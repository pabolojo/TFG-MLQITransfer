{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-09 23:08:51.406471: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-09 23:08:52.159354: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import qutip as qt\n",
    "import pickle\n",
    "\n",
    "sys.path.append('../../')\n",
    "from Pulses import *\n",
    "from Noises import Noise\n",
    "from Plots import plot_populations, plot_pulses\n",
    "from joblib import Parallel, delayed, parallel\n",
    "from tqdm.auto import tqdm\n",
    "import contextlib\n",
    "from Pulses import CTAP_pulses, STA_pulses\n",
    "from Plots import plot_best_episode\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from QEnvs.QEnvWave import QEnvWave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits = 3\n",
    "time_max = 50\n",
    "num_steps = 100\n",
    "percentage_points = 50\n",
    "omega_max = 1\n",
    "initial_state = qt.basis(3, 0)\n",
    "target_state = qt.basis(3, 2)\n",
    "noise_type = \"gaussian\"\n",
    "noise_max_percent = 0.1\n",
    "\n",
    "pulses_ctap = CTAP_pulses(num_qubits, time_max, num_steps, time_max/6, time_max/6, omega_max)\n",
    "pulses_sta = STA_pulses(num_qubits, time_max, num_steps, omega_max)\n",
    "\n",
    "pulses = np.array([pulses_ctap, pulses_sta, np.load(\"Data/CRAB_50.npy\"), np.load(\"Data/GRAPE_50.npy\")])\n",
    "\n",
    "cases = [\"CTAP\", \"STA\", \"CRAB\", \"GRAPE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_cost_function(env):\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = Noise(noise_type, 0.)\n",
    "env = QEnvWave(num_qubits=num_qubits,\n",
    "                   time_max=time_max,\n",
    "                   num_steps=num_steps,\n",
    "                   cost_function=dummy_cost_function,\n",
    "                   omega_max=omega_max,\n",
    "                   noise=noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_populations(env, pulse):\n",
    "    times = env.times\n",
    "    populations = []\n",
    "    for state in env.run_qevolution(pulse):\n",
    "        populations.append(np.abs(state))\n",
    "    return times, np.array(populations).reshape((num_steps + 1, num_qubits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_deviation_fidelities(env, pulse, number_of_runs):\n",
    "    fidelities = np.zeros(number_of_runs)\n",
    "    for i in range(number_of_runs):\n",
    "        fidelities[i] = env._quantum2rlstate(env.run_qevolution(pulse)).reshape((num_steps + 1, num_qubits))[-1,-1]\n",
    "    return np.std(fidelities)\n",
    "\n",
    "def number_of_runs(env, pulse, omega_percentage=0.005, number_of_runs=10):\n",
    "    omeag_last = 0\n",
    "    omega = standard_deviation_fidelities(env, pulse, number_of_runs)\n",
    "    while omega - omeag_last > omega_percentage:\n",
    "        number_of_runs *= 2\n",
    "        omeag_last = omega\n",
    "        omega = standard_deviation_fidelities(env, pulse, number_of_runs)\n",
    "    return number_of_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_percentage_effect(env, pulse, noise_max_percent):\n",
    "    noise_percentages = np.linspace(0, noise_max_percent, percentage_points)\n",
    "    env.noise.percentage = noise_max_percent\n",
    "    print(\"Calculating number of runs\")\n",
    "    num_runs = number_of_runs(env, pulse, omega_percentage=0.001)\n",
    "    results = np.zeros((len(noise_percentages), 2))\n",
    "    print(\"Starting probing noises\")\n",
    "    for i, noise_percentage in enumerate(noise_percentages):\n",
    "        env.noise.percentage = noise_percentage\n",
    "        fidelities = np.zeros(num_runs)\n",
    "        for j in range(num_runs):\n",
    "            fidelities[j] = env._quantum2rlstate(env.run_qevolution(pulse)).reshape((num_steps + 1, num_qubits))[-1,-1]\n",
    "        results[i, 0] = np.mean(fidelities)\n",
    "        results[i, 1] = np.std(fidelities)\n",
    "    return results, noise_percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextlib.contextmanager\n",
    "def tqdm_joblib(tqdm_object):\n",
    "    \"\"\"Context manager to patch joblib to report into tqdm progress bar.\"\"\"\n",
    "    class TqdmBatchCompletionCallback(parallel.BatchCompletionCallBack):\n",
    "        def __call__(self, *args, **kwargs):\n",
    "            tqdm_object.update(n=self.batch_size)\n",
    "            return super().__call__(*args, **kwargs)\n",
    "\n",
    "    old_batch_callback = parallel.BatchCompletionCallBack\n",
    "    parallel.BatchCompletionCallBack = TqdmBatchCompletionCallback\n",
    "    try:\n",
    "        yield tqdm_object\n",
    "    finally:\n",
    "        parallel.BatchCompletionCallBack = old_batch_callback\n",
    "        tqdm_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculations(env, label, pulse, noise_max_percent):\n",
    "    times, populations = calculate_populations(env, pulse)\n",
    "    noise_results, noise_percentages = noise_percentage_effect(env, pulse, noise_max_percent)\n",
    "    return np.array([label, times, pulse, populations, noise_percentages, noise_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d313665436734d0f9de79227186059fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing noisy transfer:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-09 23:08:56.276850: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-06-09 23:08:56.330827: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-06-09 23:08:56.423266: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-06-09 23:08:56.443513: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating number of runs\n",
      "Calculating number of runs\n",
      "Calculating number of runs\n",
      "Calculating number of runs\n",
      "Starting probing noises\n",
      "Starting probing noises\n",
      "Starting probing noises\n",
      "Starting probing noises\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_58924/3707702147.py:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/tmp/ipykernel_58924/3707702147.py:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/tmp/ipykernel_58924/3707702147.py:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/tmp/ipykernel_58924/3707702147.py:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "with tqdm_joblib(tqdm(range(len(pulses)), desc=\"Computing noisy transfer\")) as pbar:\n",
    "    results = Parallel(n_jobs=-1)(delayed(calculations)(env, cases[i], pulse, noise_max_percent) for i, pulse in enumerate(pulses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "with open(\"Data/sota_protocols_comparison_noise.pkl\", \"wb\") as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
